---
title: "Exercise Set 2"
format: 
  pdf:
    default-image-extension: png
---


```{r, setup, include=FALSE}
library(targets)
library(knitr)
opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r, include = FALSE}
tar_load_everything(strict = F, silent=T)
```

This report contains my answers for exercise set 2.

## Problem 8

### Task a

Coefficients for penguins train data fit.

```{r}
#| echo: false
print(coef(e2p8_a$fit))
```

Accuracy on training and test sets without regularisation:

```{r}
#| echo: false
print("Train accuracy:")
print(e2p8_a$train_acc)
print("Test accuracy:")
print(e2p8_a$test_acc)
```


Plot of penguins train data predictions.


```{r}
#| echo: false
e2p8a_path <- normalizePath(e2p8_a_plot)
include_graphics(e2p8a_path, rel_path = FALSE)
```



### Task b

Coefficients for penguins train data fit.

```{r}
#| echo: false
print(e2p8_b$coef_lasso)
```


Accuracy on training and test sets using lasso with regularisation:

```{r}
#| echo: false
print("Train accuracy:")
print(e2p8_b$train_acc)
print("Test accuracy:")
print(e2p8_b$test_acc)
```

### Task c

R gives warnings because the model is fitting the data too well and because there's no regulation, it will try to push probabilities closer to
0 or 1 forever if the programme didn't stop itself and give the warning.


## Problem 9

According to the textbook:

The discriminant function is linear when p=1 and all classes have a shared variance:

$$
\delta_k(x) = \frac{x \cdot \mu_k}{\sigma^2}
- \frac{\mu_k^2}{2\sigma^2}
+ \log(\pi_k)
\tag{4.18}
$$
When each class has its own variance the discriminant function becomes quadratic (non-linear):

$$
\delta_k(x) = -\frac{1}{2}(x - \mu_k)^\top \Sigma_k^{-1}(x - \mu_k)
- \frac{1}{2}\log\lvert\Sigma_k\rvert + \log \pi_k
\tag{4.28}
$$

Expanded form:

$$
\delta_k(x) = -\frac{1}{2} x^\top \Sigma_k^{-1} x
+ x^\top \Sigma_k^{-1} \mu_k
- \frac{1}{2} \mu_k^\top \Sigma_k^{-1} \mu_k
- \frac{1}{2}\log\lvert\Sigma_k\rvert + \log \pi_k
\tag{4.28}
$$

## Problem 10

### Task a

Tables of each attribute's means, standard deviations and class probabilities using Laplace smoothing:

```{r}
#| echo: false
kable(e2p10a)
```


### Task b

The posterior probability:

$$
P(Y = k \mid X = x)
=
\frac{
\pi_k \prod_{j=1}^{p} f_{k j}(x_j)
}{
\sum_{l=1}^{K} \pi_l \prod_{j=1}^{p} f_{l j}(x_j)
}
$$

For this specific case:

$$
\hat{p}(y=\text{Adelie}\mid x)
=
\frac{
\pi_{\text{Adelie}}\;\displaystyle\prod_{j=1}^{4} f_{\text{Adelie},j}(x_j)
}{
\pi_{\text{Adelie}}\;\displaystyle\prod_{j=1}^{4} f_{\text{Adelie},j}(x_j)
\;+\;
\pi_{\text{notAdelie}}\;\displaystyle\prod_{j=1}^{4} f_{\text{notAdelie},j}(x_j)
}
$$


### Task c

The posterior probabilities for the first 3 penguins:

```{r}
#| echo: false
print(head(e2p10c$prediction$posterior, n=3))
```

The accuracy score of the classifier:

```{r}
#| echo: false
print(e2p10c$accuracy)
```







